{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "#from mpi4py import MPI\n",
    "import random\n",
    "\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras.optimizers import *\n",
    "from keras.initializers import *\n",
    "from kerastuner.tuners import *\n",
    "from kerastuner import HyperModel\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from tcn import *\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set random seed\n",
    "np.random.seed(1)\n",
    "tf.random.set_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepare forecasting data\n",
    "def gen_X_sequence(id_df, seq_length, seq_cols, timesteps_pred, type_data = None):\n",
    "    \"\"\" Only sequences that meet the window-length are considered, no padding is used. This means for testing\n",
    "    we need to drop those which are below the window-length. An alternative would be to pad sequences so that\n",
    "    we can use shorter ones \"\"\"\n",
    "\n",
    "    ind_start = 0\n",
    "    \n",
    "    data_array = id_df[seq_cols].values\n",
    "    num_elements = data_array.shape[0]\n",
    "    for start, stop in zip(range(0+ind_start, num_elements-seq_length+1-timesteps_pred), range(seq_length+ind_start, num_elements+1-timesteps_pred)):\n",
    "        yield data_array[start:stop, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_Y_sequence(id_df, seq_length, seq_cols, timesteps_pred, type_data = None):\n",
    "    \"\"\" Only sequences that meet the window-length are considered, no padding is used. This means for testing\n",
    "    we need to drop those which are below the window-length. An alternative would be to pad sequences so that\n",
    "    we can use shorter ones \"\"\"\n",
    "\n",
    "    ind_start = 0\n",
    "    \n",
    "    data_array = id_df[seq_cols].values\n",
    "    num_elements = data_array.shape[0]\n",
    "    for start, stop in zip(range(0+ind_start, num_elements-seq_length+1-timesteps_pred), range(seq_length+ind_start, num_elements+1-timesteps_pred)):\n",
    "        yield data_array[stop-1, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset(sequence_length, batch_size):\n",
    "    # set folder path\n",
    "    folder = 'data'\n",
    "    fd = folder\n",
    "    fd_km = fd\n",
    "\n",
    "    # import data\n",
    "    data_train_df = pd.read_pickle(fd_km + '/data_train_v1').reset_index().iloc[:,1:] #full set\n",
    "    data_test_df = pd.read_pickle(fd_km + '/data_test_v1').reset_index().iloc[:,1:]\n",
    "\n",
    "    # create bins\n",
    "    l = 0.5\n",
    "    nb_bins = 20 # including one extra bin for RUL>upper_bin_bound\n",
    "    lower_bin_bound = 0\n",
    "    upper_bin_bound = 80000\n",
    "\n",
    "    bins = np.linspace(lower_bin_bound**l, upper_bin_bound**l, nb_bins)**(1/l)\n",
    "    bins = np.append(bins, data_train_df.RUL.max())\n",
    "\n",
    "    labels=[i for i in range(bins.shape[0]-1)]\n",
    "\n",
    "    # categorise data\n",
    "    data_train_df['RUL_bin'] = pd.cut(data_train_df['RUL'], bins=bins, labels=labels)\n",
    "    data_test_df['RUL_bin'] = pd.cut(data_test_df['RUL'], bins=bins, labels=labels)\n",
    "\n",
    "    # build data sequences\n",
    "    #data_train_group = [data_train_df for _, data_train_df in data_train_df.groupby('ID')]\n",
    "    #random.shuffle(data_train_group)\n",
    "    #data_train_df_random = pd.concat(data_train_group)\n",
    "\n",
    "    data_train = data_train_df[data_train_df.ID <= 100]\n",
    "    data_val = data_train_df[data_train_df.ID > 9900]\n",
    "    data_test = data_test_df\n",
    "\n",
    "    #prepare data\n",
    "    seq_cols = ['gauge'+str(i) for i in range(1,4)]\n",
    "    seq_cols1 = ['RUL_bin']\n",
    "    timesteps_pred = 1\n",
    "\n",
    "    #training set\n",
    "    seq_gen = (list(gen_X_sequence(data_train[data_train['ID']==id], sequence_length, seq_cols, timesteps_pred, type_data= 'train')) \n",
    "                    for id in data_train['ID'].unique())\n",
    "    # generate sequences and convert to numpy array\n",
    "    dbX = np.concatenate(list(seq_gen))\n",
    "\n",
    "    seq_gen = (list(gen_Y_sequence(data_train[data_train['ID']==id], sequence_length, seq_cols1, timesteps_pred, type_data= 'train')) \n",
    "                    for id in data_train['ID'].unique())\n",
    "    # generate sequences and convert to numpy array\n",
    "    dbY = np.concatenate(list(seq_gen)).reshape(-1,)\n",
    "\n",
    "    #val set\n",
    "    seq_gen = (list(gen_X_sequence(data_val[data_val['ID']==id], sequence_length, seq_cols, timesteps_pred, type_data= 'train')) \n",
    "                    for id in data_val['ID'].unique())\n",
    "    # generate sequences and convert to numpy array\n",
    "    dbX_val = np.concatenate(list(seq_gen))\n",
    "\n",
    "    seq_gen = (list(gen_Y_sequence(data_val[data_val['ID']==id], sequence_length, seq_cols1, timesteps_pred, type_data= 'train')) \n",
    "                    for id in data_val['ID'].unique())\n",
    "    # generate sequences and convert to numpy array\n",
    "    dbY_val = np.concatenate(list(seq_gen)).reshape(-1,)\n",
    "\n",
    "    #test set\n",
    "    seq_gen = (list(gen_X_sequence(data_test[data_test['ID']==id], sequence_length, seq_cols, timesteps_pred, type_data= 'train')) \n",
    "                    for id in data_test['ID'].unique())\n",
    "    # generate sequences and convert to numpy array\n",
    "    dbX_test = np.concatenate(list(seq_gen))\n",
    "\n",
    "    seq_gen = (list(gen_Y_sequence(data_test[data_test['ID']==id], sequence_length, seq_cols1, timesteps_pred, type_data= 'train')) \n",
    "                    for id in data_test['ID'].unique())\n",
    "    # generate sequences and convert to numpy array\n",
    "    dbY_test = np.concatenate(list(seq_gen)).reshape(-1,)\n",
    "\n",
    "    return (\n",
    "        tf.data.Dataset.from_tensor_slices((dbX, dbY)).batch(batch_size),\n",
    "        tf.data.Dataset.from_tensor_slices((dbX_val, dbY_val)).batch(batch_size),\n",
    "        tf.data.Dataset.from_tensor_slices((dbX_test, dbY_test)).batch(batch_size),\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class MyHyperModel(HyperModel):\n",
    "\n",
    "    def __init__(self, input_shape, output_shape):\n",
    "        self.input_shape = input_shape\n",
    "        self.output_shape = output_shape\n",
    "\n",
    "    def build(self, hp):\n",
    "        # build model\n",
    "        input_layer = Input(shape=self.input_shape)\n",
    "        x = TCN(nb_filters=hp.Int('nb_filters', min_value=10, max_value=50, step=5),\n",
    "                    kernel_size=hp.Int('kernel_size', min_value=3, max_value=9, step=3),\n",
    "                    nb_stacks=1,\n",
    "                    dilations=[2 ** i for i in range(hp.Int('dilations', min_value=4, max_value=10, step=2))],\n",
    "                    padding='causal',\n",
    "                    use_skip_connections=hp.Choice('use_skip_connections', values=[False, True]),\n",
    "                    dropout_rate=hp.Float('dropout_rate', min_value=0.0, max_value=0.2, step=0.1),\n",
    "                    return_sequences=False,\n",
    "                    activation='relu',\n",
    "                    kernel_initializer='he_normal',\n",
    "                    use_batch_norm=False, use_layer_norm=False, use_weight_norm=True,\n",
    "                    name='TCN')(input_layer)\n",
    "\n",
    "        x = Dense(self.output_shape, activation='softmax')(x)\n",
    "        output_layer = x\n",
    "\n",
    "        model = Model(input_layer, output_layer)\n",
    "\n",
    "        # compile model\n",
    "        model.compile(\n",
    "            optimizer=Adam(hp.Choice('learning_rate', values=[1e-2, 1e-3])),\n",
    "            loss='sparse_categorical_crossentropy',\n",
    "            metrics=['SparseCategoricalAccuracy'])\n",
    "\n",
    "        return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data and execute training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load training, validation and test data\n",
    "batch_size = 4096\n",
    "sequence_length = 30\n",
    "train_dataset, val_dataset, test_dataset = get_dataset(\n",
    "    sequence_length=sequence_length, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce.\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)\n",
      "Number of devices: 1\n"
     ]
    }
   ],
   "source": [
    "# Create a MirroredStrategy.\n",
    "strategy = tf.distribute.MirroredStrategy()\n",
    "print(\"Number of devices: {}\".format(strategy.num_replicas_in_sync))\n",
    "\n",
    "# Open a strategy scope.\n",
    "with strategy.scope():\n",
    "    # Everything that creates variables should be under the strategy scope.\n",
    "    # In general this is only model construction & `compile()`.\n",
    "    hypermodel = MyHyperModel(input_shape = (30, 3), output_shape = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search space summary\n",
      "Default search space size: 6\n",
      "nb_filters (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 10, 'max_value': 50, 'step': 5, 'sampling': None}\n",
      "kernel_size (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 3, 'max_value': 9, 'step': 3, 'sampling': None}\n",
      "dilations (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 4, 'max_value': 10, 'step': 2, 'sampling': None}\n",
      "use_skip_connections (Choice)\n",
      "{'default': 0, 'conditions': [], 'values': [0, 1], 'ordered': True}\n",
      "dropout_rate (Float)\n",
      "{'default': 0.0, 'conditions': [], 'min_value': 0.0, 'max_value': 0.2, 'step': 0.1, 'sampling': None}\n",
      "learning_rate (Choice)\n",
      "{'default': 0.01, 'conditions': [], 'values': [0.01, 0.001], 'ordered': True}\n"
     ]
    }
   ],
   "source": [
    "tuner = RandomSearch(\r\n",
    "    hypermodel,\r\n",
    "    objective='val_sparse_categorical_accuracy',\r\n",
    "    max_trials=100,\r\n",
    "    executions_per_trial=1,\r\n",
    "    directory='CNN_Model3_6',\r\n",
    "    project_name='100_structures_randomSearch_1')\r\n",
    "\r\n",
    "tuner.search_space_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Search: Running Trial #1\n",
      "\n",
      "Hyperparameter    |Value             |Best Value So Far \n",
      "nb_filters        |30                |?                 \n",
      "kernel_size       |3                 |?                 \n",
      "dilations         |6                 |?                 \n",
      "use_skip_connec...|1                 |?                 \n",
      "dropout_rate      |0.1               |?                 \n",
      "learning_rate     |0.001             |?                 \n",
      "\n",
      "Epoch 1/200\n",
      "WARNING:tensorflow:From C:\\Users\\pajo8\\anaconda3\\envs\\RUL-Prediction\\lib\\site-packages\\tensorflow\\python\\ops\\summary_ops_v2.py:1277: stop (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n",
      "Instructions for updating:\n",
      "use `tf.profiler.experimental.stop` instead.\n",
      "3/3 - 13s - loss: 3.9162 - sparse_categorical_accuracy: 0.0919 - val_loss: 2.8443 - val_sparse_categorical_accuracy: 0.1648\n",
      "Epoch 2/200\n",
      "3/3 - 8s - loss: 3.1057 - sparse_categorical_accuracy: 0.1050 - val_loss: 2.7163 - val_sparse_categorical_accuracy: 0.1165\n",
      "Epoch 3/200\n",
      "3/3 - 6s - loss: 2.9006 - sparse_categorical_accuracy: 0.1126 - val_loss: 2.6192 - val_sparse_categorical_accuracy: 0.1477\n",
      "Epoch 4/200\n",
      "3/3 - 6s - loss: 2.7656 - sparse_categorical_accuracy: 0.1201 - val_loss: 2.5267 - val_sparse_categorical_accuracy: 0.1637\n",
      "Epoch 5/200\n",
      "3/3 - 6s - loss: 2.6771 - sparse_categorical_accuracy: 0.1339 - val_loss: 2.4380 - val_sparse_categorical_accuracy: 0.1752\n",
      "Epoch 6/200\n",
      "3/3 - 6s - loss: 2.6035 - sparse_categorical_accuracy: 0.1425 - val_loss: 2.3548 - val_sparse_categorical_accuracy: 0.1823\n",
      "Epoch 7/200\n",
      "3/3 - 6s - loss: 2.5446 - sparse_categorical_accuracy: 0.1425 - val_loss: 2.2788 - val_sparse_categorical_accuracy: 0.1850\n",
      "Epoch 8/200\n",
      "3/3 - 7s - loss: 2.4779 - sparse_categorical_accuracy: 0.1574 - val_loss: 2.2018 - val_sparse_categorical_accuracy: 0.1882\n",
      "Epoch 9/200\n",
      "3/3 - 5s - loss: 2.4341 - sparse_categorical_accuracy: 0.1617 - val_loss: 2.1380 - val_sparse_categorical_accuracy: 0.1889\n",
      "Epoch 10/200\n",
      "3/3 - 5s - loss: 2.3959 - sparse_categorical_accuracy: 0.1653 - val_loss: 2.0887 - val_sparse_categorical_accuracy: 0.2564\n",
      "Epoch 11/200\n",
      "3/3 - 6s - loss: 2.3412 - sparse_categorical_accuracy: 0.1748 - val_loss: 2.0355 - val_sparse_categorical_accuracy: 0.1942\n",
      "Epoch 12/200\n",
      "3/3 - 7s - loss: 2.2962 - sparse_categorical_accuracy: 0.1899 - val_loss: 1.9940 - val_sparse_categorical_accuracy: 0.2318\n",
      "Epoch 13/200\n",
      "3/3 - 7s - loss: 2.2501 - sparse_categorical_accuracy: 0.1911 - val_loss: 1.9430 - val_sparse_categorical_accuracy: 0.2456\n",
      "Epoch 14/200\n",
      "3/3 - 7s - loss: 2.2024 - sparse_categorical_accuracy: 0.2065 - val_loss: 1.8818 - val_sparse_categorical_accuracy: 0.2914\n",
      "Epoch 15/200\n",
      "3/3 - 6s - loss: 2.1568 - sparse_categorical_accuracy: 0.2169 - val_loss: 1.8242 - val_sparse_categorical_accuracy: 0.3155\n",
      "Epoch 16/200\n",
      "3/3 - 8s - loss: 2.1066 - sparse_categorical_accuracy: 0.2252 - val_loss: 1.7658 - val_sparse_categorical_accuracy: 0.4344\n",
      "Epoch 17/200\n",
      "3/3 - 6s - loss: 2.0715 - sparse_categorical_accuracy: 0.2337 - val_loss: 1.7156 - val_sparse_categorical_accuracy: 0.4195\n",
      "Epoch 18/200\n",
      "3/3 - 6s - loss: 2.0251 - sparse_categorical_accuracy: 0.2393 - val_loss: 1.6735 - val_sparse_categorical_accuracy: 0.3661\n",
      "Epoch 19/200\n",
      "3/3 - 7s - loss: 1.9835 - sparse_categorical_accuracy: 0.2491 - val_loss: 1.6261 - val_sparse_categorical_accuracy: 0.4079\n",
      "Epoch 20/200\n",
      "3/3 - 6s - loss: 1.9567 - sparse_categorical_accuracy: 0.2573 - val_loss: 1.5867 - val_sparse_categorical_accuracy: 0.3999\n",
      "Epoch 21/200\n",
      "3/3 - 7s - loss: 1.9087 - sparse_categorical_accuracy: 0.2654 - val_loss: 1.5535 - val_sparse_categorical_accuracy: 0.3791\n",
      "Epoch 22/200\n",
      "3/3 - 6s - loss: 1.8735 - sparse_categorical_accuracy: 0.2705 - val_loss: 1.5216 - val_sparse_categorical_accuracy: 0.3860\n",
      "Epoch 23/200\n",
      "3/3 - 6s - loss: 1.8328 - sparse_categorical_accuracy: 0.2837 - val_loss: 1.4837 - val_sparse_categorical_accuracy: 0.4088\n",
      "Epoch 24/200\n",
      "3/3 - 6s - loss: 1.7957 - sparse_categorical_accuracy: 0.2926 - val_loss: 1.4500 - val_sparse_categorical_accuracy: 0.4226\n",
      "Epoch 25/200\n",
      "3/3 - 6s - loss: 1.7509 - sparse_categorical_accuracy: 0.3091 - val_loss: 1.4167 - val_sparse_categorical_accuracy: 0.4513\n",
      "Epoch 26/200\n",
      "3/3 - 7s - loss: 1.7125 - sparse_categorical_accuracy: 0.3131 - val_loss: 1.3811 - val_sparse_categorical_accuracy: 0.4557\n",
      "Epoch 27/200\n",
      "3/3 - 7s - loss: 1.6910 - sparse_categorical_accuracy: 0.3257 - val_loss: 1.3489 - val_sparse_categorical_accuracy: 0.4713\n",
      "Epoch 28/200\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-ec2415366ddb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m tuner.search(train_dataset,\n\u001b[0m\u001b[0;32m      2\u001b[0m              \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m200\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m              \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m              \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mval_dataset\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m              callbacks=[tf.keras.callbacks.TensorBoard(tuner.directory + '/' + tuner.project_name)])\n",
      "\u001b[1;32m~\\anaconda3\\envs\\RUL-Prediction\\lib\\site-packages\\kerastuner\\engine\\base_tuner.py\u001b[0m in \u001b[0;36msearch\u001b[1;34m(self, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_trial_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 131\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_trial\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    132\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_trial_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_search_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\RUL-Prediction\\lib\\site-packages\\kerastuner\\engine\\multi_execution_tuner.py\u001b[0m in \u001b[0;36mrun_trial\u001b[1;34m(self, trial, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[0;32m     94\u001b[0m             \u001b[0mcopied_fit_kwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'callbacks'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 96\u001b[1;33m             \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_build_and_fit_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfit_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopied_fit_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     97\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mmetric\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch_values\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     98\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moracle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobjective\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdirection\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'min'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\RUL-Prediction\\lib\\site-packages\\kerastuner\\engine\\tuner.py\u001b[0m in \u001b[0;36m_build_and_fit_model\u001b[1;34m(self, trial, fit_args, fit_kwargs)\u001b[0m\n\u001b[0;32m    139\u001b[0m         \"\"\"\n\u001b[0;32m    140\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhypermodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhyperparameters\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 141\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    142\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    143\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mrun_trial\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrial\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\RUL-Prediction\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    106\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m     \u001b[1;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\RUL-Prediction\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[0;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1098\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1099\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\RUL-Prediction\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    778\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 780\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    781\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\RUL-Prediction\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    805\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    806\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 807\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    808\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    809\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\RUL-Prediction\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2829\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2830\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2831\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\RUL-Prediction\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1841\u001b[0m       \u001b[0;31m`\u001b[0m\u001b[0margs\u001b[0m\u001b[0;31m`\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1842\u001b[0m     \"\"\"\n\u001b[1;32m-> 1843\u001b[1;33m     return self._call_flat(\n\u001b[0m\u001b[0;32m   1844\u001b[0m         [t for t in nest.flatten((args, kwargs), expand_composites=True)\n\u001b[0;32m   1845\u001b[0m          if isinstance(t, (ops.Tensor,\n",
      "\u001b[1;32m~\\anaconda3\\envs\\RUL-Prediction\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1921\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1922\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1923\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1924\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32m~\\anaconda3\\envs\\RUL-Prediction\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    543\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 545\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    546\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    547\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\RUL-Prediction\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "tuner.search(train_dataset,\n",
    "             epochs=200,\n",
    "             verbose=2,\n",
    "             validation_data=val_dataset,\n",
    "             callbacks=[tf.keras.callbacks.TensorBoard(tuner.directory + '/' + tuner.project_name)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the TensorBoard notebook extension\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "ERROR: Timed out waiting for TensorBoard to start. It may still be running as pid 22312."
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir \"C:\\Users\\pajo8\\RUL Prediction\\CNN_Model3_6\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Look at results and save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results summary\n",
      "Results in CNN_Model3_6\\100_structures_randomSearch_1\n",
      "Showing 10 best trials\n",
      "Objective(name='val_sparse_categorical_accuracy', direction='max')\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "nb_filters: 20\n",
      "kernel_size: 3\n",
      "dilations: 4\n",
      "use_skip_connections: 0\n",
      "dropout_rate: 0.0\n",
      "learning_rate: 0.01\n",
      "Score: 0.7395995259284973\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "nb_filters: 15\n",
      "kernel_size: 9\n",
      "dilations: 6\n",
      "use_skip_connections: 1\n",
      "dropout_rate: 0.0\n",
      "learning_rate: 0.01\n",
      "Score: 0.7150955200195312\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "nb_filters: 25\n",
      "kernel_size: 9\n",
      "dilations: 8\n",
      "use_skip_connections: 0\n",
      "dropout_rate: 0.0\n",
      "learning_rate: 0.01\n",
      "Score: 0.7107982039451599\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "nb_filters: 35\n",
      "kernel_size: 6\n",
      "dilations: 10\n",
      "use_skip_connections: 1\n",
      "dropout_rate: 0.0\n",
      "learning_rate: 0.01\n",
      "Score: 0.6979976296424866\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "nb_filters: 15\n",
      "kernel_size: 6\n",
      "dilations: 4\n",
      "use_skip_connections: 0\n",
      "dropout_rate: 0.2\n",
      "learning_rate: 0.01\n",
      "Score: 0.6964432597160339\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "nb_filters: 45\n",
      "kernel_size: 9\n",
      "dilations: 4\n",
      "use_skip_connections: 0\n",
      "dropout_rate: 0.2\n",
      "learning_rate: 0.01\n",
      "Score: 0.6949803233146667\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "nb_filters: 25\n",
      "kernel_size: 9\n",
      "dilations: 8\n",
      "use_skip_connections: 1\n",
      "dropout_rate: 0.2\n",
      "learning_rate: 0.01\n",
      "Score: 0.6934260129928589\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "nb_filters: 20\n",
      "kernel_size: 3\n",
      "dilations: 6\n",
      "use_skip_connections: 0\n",
      "dropout_rate: 0.2\n",
      "learning_rate: 0.01\n",
      "Score: 0.6890372037887573\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "nb_filters: 50\n",
      "kernel_size: 9\n",
      "dilations: 6\n",
      "use_skip_connections: 1\n",
      "dropout_rate: 0.1\n",
      "learning_rate: 0.001\n",
      "Score: 0.6853799223899841\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "nb_filters: 10\n",
      "kernel_size: 6\n",
      "dilations: 6\n",
      "use_skip_connections: 0\n",
      "dropout_rate: 0.0\n",
      "learning_rate: 0.001\n",
      "Score: 0.6822711825370789\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n"
     ]
    }
   ],
   "source": [
    "models = tuner.get_best_models(num_models=1)\n",
    "\n",
    "tuner.results_summary()\n",
    "\n",
    "best_model = models[0]\n",
    "\n",
    "model_path = tuner.directory + '/' + tuner.project_name + '/' + 'best_model'\n",
    "\n",
    "# get model as json string and save to file\n",
    "model_as_json = best_model.to_json()\n",
    "with open(model_path + '.json', \"w\") as json_file:\n",
    "    json_file.write(model_as_json)\n",
    "# save model weights\n",
    "best_model.save_weights(model_path + '_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('RUL-Prediction': conda)",
   "name": "python388jvsc74a57bd0742b229cc72d044b71b2444ce71ada2703e45c0271c584dd49e5f92cbb53c451"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}